{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceb83df4-5085-4db6-a3ed-d5523512df2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import load, asarray, zeros, ones, savez_compressed\n",
    "from numpy.random import randn, randint\n",
    "from skimage.transform import resize\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, Conv2D\n",
    "from tensorflow.keras.layers import UpSampling2D, AveragePooling2D, LeakyReLU, Layer, Add\n",
    "from keras.constraints import max_norm\n",
    "from keras.initializers import RandomNormal\n",
    "import mtcnn\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from matplotlib import pyplot\n",
    "import cv2\n",
    "import os\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ea42bc8-dc37-4573-943c-a89e7f6fa5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the image file\n",
    "def load_image(filename):\n",
    "    image = Image.open(filename)\n",
    "    image = image.convert('RGB')\n",
    "    pixels = asarray(image)\n",
    "    return pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d89c7e0-573e-4106-8552-a163542dc958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the face from a loaded image and resize\n",
    "def extract_face(model, pixels, required_size=(128, 128)):\n",
    "    # detect face in the image\n",
    "    faces = model.detect_faces(pixels)\n",
    "    if len(faces) == 0:\n",
    "        return None\n",
    "\n",
    "    # extract details of the face\n",
    "    x1, y1, width, height = faces[0]['box']\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    face_pixels = pixels[y1:y2, x1:x2]\n",
    "    image = Image.fromarray(face_pixels)\n",
    "    image = image.resize(required_size)\n",
    "    face_array = asarray(image)\n",
    "\n",
    "    return face_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37c3ee18-bfd9-4f1c-8cd2-b4c2a2b32fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and extract faces for all images in a directory\n",
    "def load_faces(directory, n_faces):\n",
    "    # prepare model\n",
    "    model = MTCNN()\n",
    "    faces = list()\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        # Computing the retrieval and extraction of faces\n",
    "        display.clear_output(wait=True)\n",
    "        \n",
    "        pixels = load_image(directory + filename)\n",
    "        face = extract_face(model, pixels)\n",
    "        if face is None:\n",
    "            continue\n",
    "        faces.append(face)\n",
    "        print(len(faces), face.shape)\n",
    "        if len(faces) >= n_faces:\n",
    "            break\n",
    "\n",
    "    return asarray(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6114a4b8-033c-4e45-881a-f9983b0e76ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:  (10000, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load and extract all faces \n",
    "try:\n",
    "    data = load('img_align_celeba_128.npz')\n",
    "    faces = data['arr_0']\n",
    "    print('Loaded: ', faces.shape)\n",
    "except:\n",
    "    directory = 'CelebA_Dataset/img_align_celeba/img_align_celeba/'\n",
    "    all_faces = load_faces(directory, 10000)\n",
    "    print(\"Loaded: \", all_faces.shape)\n",
    "    \n",
    "    # save in compressed format\n",
    "    savez_compressed('img_align_celeba_128.npz', all_faces)\n",
    "    data = load('img_align_celeba_128.npz')\n",
    "    faces = data['arr_0']\n",
    "    print('Loaded: ', faces.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "927db1bc-c1ca-40b0-902c-8e0dbd9d0a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel-wise feature vector normalization layer\n",
    "class PixelNormalization(Layer):\n",
    "    # initialize the layer\n",
    "    def __init__(self, **kwargs):\n",
    "        super(PixelNormalization, self).__init__(**kwargs)\n",
    " \n",
    "    # perform the operation\n",
    "    def call(self, inputs):\n",
    "        # computing pixel values\n",
    "        values = inputs**2.0\n",
    "        mean_values = tf.keras.backend.mean(values, axis=-1, keepdims=True)\n",
    "        mean_values += 1.0e-8\n",
    "        l2 = tf.keras.backend.sqrt(mean_values)\n",
    "        normalized = inputs / l2\n",
    "        return normalized\n",
    " \n",
    "    # define the output shape of the layer\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4445e97-ac9f-4c20-a470-731b98d1da01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini-batch standard deviation layer\n",
    "class MinibatchStdev(Layer):\n",
    "    # initialize the layer\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MinibatchStdev, self).__init__(**kwargs)\n",
    " \n",
    "    # perform the operation\n",
    "    def call(self, inputs):\n",
    "        mean = tf.keras.backend.mean(inputs, axis=0, keepdims=True)\n",
    "        squ_diffs = tf.keras.backend.square(inputs - mean)\n",
    "        mean_sq_diff = tf.keras.backend.mean(squ_diffs, axis=0, keepdims=True)\n",
    "        mean_sq_diff += 1e-8\n",
    "        stdev = tf.keras.backend.sqrt(mean_sq_diff)\n",
    "        \n",
    "        mean_pix = tf.keras.backend.mean(stdev, keepdims=True)\n",
    "        shape = tf.keras.backend.shape(inputs)\n",
    "        output = tf.keras.backend.tile(mean_pix, (shape[0], shape[1], shape[2], 1))\n",
    "        \n",
    "        combined = tf.keras.backend.concatenate([inputs, output], axis=-1)\n",
    "        return combined\n",
    " \n",
    "    # define the output shape of the layer\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        input_shape = list(input_shape)\n",
    "        input_shape[-1] += 1\n",
    "        return tuple(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "704f4ccb-c92f-4106-b872-4e6c9d5cbfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted sum output\n",
    "class WeightedSum(Add):\n",
    "    # init with default value\n",
    "    def __init__(self, alpha=0.0, **kwargs):\n",
    "        super(WeightedSum, self).__init__(**kwargs)\n",
    "        self.alpha = tf.keras.backend.variable(alpha, name='ws_alpha')\n",
    " \n",
    "    # output a weighted sum of inputs\n",
    "    def _merge_function(self, inputs):\n",
    "        # only supports a weighted sum of two inputs\n",
    "        assert (len(inputs) == 2)\n",
    "        # ((1-a) * input1) + (a * input2)\n",
    "        output = ((1.0 - self.alpha) * inputs[0]) + (self.alpha * inputs[1])\n",
    "        return output\n",
    "\n",
    "# calculate wasserstein loss\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return tf.keras.backend.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e0eebd4-ed13-4e6a-b7a0-06484f423a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "def load_real_samples(filename):\n",
    "    data = load(filename)\n",
    "    X = data['arr_0']\n",
    "    X = X.astype('float32')\n",
    "    X = (X - 127.5) / 127.5\n",
    "    return X\n",
    " \n",
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    X = dataset[ix]\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y\n",
    " \n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n",
    " \n",
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    X = generator.predict(x_input)\n",
    "    y = -ones((n_samples, 1))\n",
    "    return X, y\n",
    " \n",
    "# update the alpha value on each instance of WeightedSum\n",
    "def update_fadein(models, step, n_steps):\n",
    "    alpha = step / float(n_steps - 1)\n",
    "    for model in models:\n",
    "        for layer in model.layers:\n",
    "            if isinstance(layer, WeightedSum):\n",
    "                tf.keras.backend.set_value(layer.alpha, alpha)\n",
    "                \n",
    "# scale images to preferred size\n",
    "def scale_dataset(images, new_shape):\n",
    "    images_list = list()\n",
    "    for image in images:\n",
    "        new_image = resize(image, new_shape, 0)\n",
    "        images_list.append(new_image)\n",
    "    return asarray(images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd880283-014b-4745-a71c-74e8d1e86138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a generator block\n",
    "def add_generator_block(old_model):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    const = max_norm(1.0)\n",
    "    block_end = old_model.layers[-2].output\n",
    "    \n",
    "    # upsample, and define new block\n",
    "    upsampling = UpSampling2D()(block_end)\n",
    "    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(upsampling)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    \n",
    "    out_image = Conv2D(3, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    model1 = Model(old_model.input, out_image)\n",
    "    out_old = old_model.layers[-1]\n",
    "    out_image2 = out_old(upsampling)\n",
    "    \n",
    "    merged = WeightedSum()([out_image2, out_image])\n",
    "    model2 = Model(old_model.input, merged)\n",
    "    return [model1, model2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62bec3b5-cf0f-4a5b-b3ea-0d5dbb963341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define generator models\n",
    "def define_generator(latent_dim, n_blocks, in_dim=4):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    const = max_norm(1.0)\n",
    "    model_list = list()\n",
    "    in_latent = Input(shape=(latent_dim,))\n",
    "    g  = Dense(128 * in_dim * in_dim, kernel_initializer=init, kernel_constraint=const)(in_latent)\n",
    "    g = Reshape((in_dim, in_dim, 128))(g)\n",
    "    \n",
    "    # conv 4x4, input block\n",
    "    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    \n",
    "    # conv 3x3\n",
    "    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    \n",
    "    # conv 1x1, output block\n",
    "    out_image = Conv2D(3, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    model = Model(in_latent, out_image)\n",
    "    model_list.append([model, model])\n",
    "    \n",
    "    for i in range(1, n_blocks):\n",
    "        old_model = model_list[i - 1][0]\n",
    "        models = add_generator_block(old_model)\n",
    "        model_list.append(models)\n",
    "        \n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dd77cc2-973f-4e58-b603-b3a1147d8c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a discriminator block\n",
    "def add_discriminator_block(old_model, n_input_layers=3):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    const = max_norm(1.0)\n",
    "    in_shape = list(old_model.input.shape)\n",
    "    \n",
    "    # define new input shape as double the size\n",
    "    input_shape = (in_shape[-2]*2, in_shape[-2]*2, in_shape[-1])\n",
    "    in_image = Input(shape=input_shape)\n",
    "    \n",
    "    # define new input processing layer\n",
    "    d = Conv2D(128, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(in_image)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    # define new block\n",
    "    d = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = AveragePooling2D((2, 2))(d)\n",
    "    block_new = d\n",
    "    \n",
    "    # skip the input, 1x1 and activation for the old model\n",
    "    for i in range(n_input_layers, len(old_model.layers)):\n",
    "        d = old_model.layers[i](d)\n",
    "    model1 = Model(in_image, d)\n",
    "    \n",
    "    model1.compile(loss=wasserstein_loss, optimizer=Adam(learning_rate=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "    \n",
    "    downsample = AveragePooling2D(pool_size=(2, 2))(in_image)\n",
    "    \n",
    "    block_old = old_model.layers[1](downsample)\n",
    "    block_old = old_model.layers[2](block_old)\n",
    "    d = WeightedSum()([block_old, block_new])\n",
    "    \n",
    "    for i in range(n_input_layers, len(old_model.layers)):\n",
    "        d = old_model.layers[i](d)\n",
    "        \n",
    "    model2 = Model(in_image, d)\n",
    "    \n",
    "    model2.compile(loss=wasserstein_loss, optimizer=Adam(learning_rate=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "    return [model1, model2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "672e0d53-0c3e-4fe8-9c4e-c99a79aa7409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the discriminator models for each image resolution\n",
    "def define_discriminator(n_blocks, input_shape=(4,4,3)):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    const = max_norm(1.0)\n",
    "    model_list = list()\n",
    "    in_image = Input(shape=input_shape)\n",
    "    \n",
    "    d = Conv2D(128, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(in_image)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = MinibatchStdev()(d)\n",
    "    \n",
    "    d = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = Conv2D(128, (4,4), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = Flatten()(d)\n",
    "    out_class = Dense(1)(d)\n",
    "    \n",
    "    model = Model(in_image, out_class)\n",
    "    model.compile(loss=wasserstein_loss, optimizer=Adam(learning_rate=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "    model_list.append([model, model])\n",
    "    \n",
    "    for i in range(1, n_blocks):\n",
    "        old_model = model_list[i - 1][0]\n",
    "        models = add_discriminator_block(old_model)\n",
    "        model_list.append(models)\n",
    "        \n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cca3f699-b571-445b-b409-3142ad5683a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define composite models for training generators via discriminators\n",
    "\n",
    "def define_composite(discriminators, generators):\n",
    "    model_list = list()\n",
    "    # create composite models\n",
    "    for i in range(len(discriminators)):\n",
    "        g_models, d_models = generators[i], discriminators[i]\n",
    "        # straight-through model\n",
    "        d_models[0].trainable = False\n",
    "        model1 = Sequential()\n",
    "        model1.add(g_models[0])\n",
    "        model1.add(d_models[0])\n",
    "        model1.compile(loss=wasserstein_loss, optimizer=Adam(learning_rate=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "        # fade-in model\n",
    "        d_models[1].trainable = False\n",
    "        model2 = Sequential()\n",
    "        model2.add(g_models[1])\n",
    "        model2.add(d_models[1])\n",
    "        model2.compile(loss=wasserstein_loss, optimizer=Adam(learning_rate=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "        # store\n",
    "        model_list.append([model1, model2])\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f4d2550-e2f9-4f97-8a5a-d1e1ab7b9bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a generator and discriminator\n",
    "def train_epochs(g_model, d_model, gan_model, dataset, n_epochs, n_batch, fadein=False):\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    half_batch = int(n_batch / 2)\n",
    "    \n",
    "    for i in range(n_steps):\n",
    "        # update alpha for all WeightedSum layers when fading in new blocks\n",
    "        display.clear_output(wait=True)\n",
    "        \n",
    "        if fadein:\n",
    "            update_fadein([g_model, d_model, gan_model], i, n_steps)\n",
    "        # prepare real and fake samples\n",
    "        X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "        X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "        \n",
    "        # update discriminator model\n",
    "        d_loss1 = d_model.train_on_batch(X_real, y_real)\n",
    "        d_loss2 = d_model.train_on_batch(X_fake, y_fake)\n",
    "        \n",
    "        # update the generator via the discriminator's error\n",
    "        z_input = generate_latent_points(latent_dim, n_batch)\n",
    "        y_real2 = ones((n_batch, 1))\n",
    "        g_loss = gan_model.train_on_batch(z_input, y_real2)\n",
    "        \n",
    "        # summarize loss on this batch\n",
    "        print('>%d, d1=%.3f, d2=%.3f g=%.3f' % (i+1, d_loss1, d_loss2, g_loss))\n",
    "        \n",
    "# train the generator and discriminator\n",
    "def train(g_models, d_models, gan_models, dataset, latent_dim, e_norm, e_fadein, n_batch):\n",
    "    g_normal, d_normal, gan_normal = g_models[0][0], d_models[0][0], gan_models[0][0]\n",
    "    gen_shape = g_normal.output_shape\n",
    "    scaled_data = scale_dataset(dataset, gen_shape[1:])\n",
    "    print('Scaled Data', scaled_data.shape)\n",
    "\n",
    "    # train normal or straight-through models\n",
    "    train_epochs(g_normal, d_normal, gan_normal, scaled_data, e_norm[0], n_batch[0])\n",
    "    summarize_performance('tuned', g_normal, latent_dim)\n",
    "    \n",
    "    # process each level of growth\n",
    "    for i in range(1, len(g_models)):\n",
    "        # retrieve models for this level of growth\n",
    "        [g_normal, g_fadein] = g_models[i]\n",
    "        [d_normal, d_fadein] = d_models[i]\n",
    "        [gan_normal, gan_fadein] = gan_models[i]\n",
    "        \n",
    "        # scale dataset to appropriate size\n",
    "        gen_shape = g_normal.output_shape\n",
    "        scaled_data = scale_dataset(dataset, gen_shape[1:])\n",
    "        print('Scaled Data', scaled_data.shape)\n",
    "        \n",
    "        # train fade-in models for next level of growth\n",
    "        train_epochs(g_fadein, d_fadein, gan_fadein, scaled_data, e_fadein[i], n_batch[i], True)\n",
    "        summarize_performance('faded', g_fadein, latent_dim)\n",
    "        \n",
    "        # train normal or straight-through models\n",
    "        train_epochs(g_normal, d_normal, gan_normal, scaled_data, e_norm[i], n_batch[i])\n",
    "        summarize_performance('tuned', g_normal, latent_dim)\n",
    "\n",
    "        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51773649-a40c-4f69-8a2b-5f87d978e153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(status, g_model, latent_dim, n_samples=25):\n",
    "    gen_shape = g_model.output_shape\n",
    "    name = '%03dx%03d-%s' % (gen_shape[1], gen_shape[2], status)\n",
    "    \n",
    "    X, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "    X = (X - X.min()) / (X.max() - X.min())\n",
    "    \n",
    "    square = int(sqrt(n_samples))\n",
    "    for i in range(n_samples):\n",
    "        pyplot.subplot(square, square, 1 + i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(X[i])\n",
    "        \n",
    "    # save plot to file\n",
    "    filename1 = 'plot_%s.png' % (name)\n",
    "    pyplot.savefig(filename1)\n",
    "    pyplot.close()\n",
    "    \n",
    "    filename2 = 'model_%s.h5' % (name)\n",
    "    g_model.save(filename2)\n",
    "    print('>Saved: %s and %s' % (filename1, filename2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72db52e-c7e7-4289-af82-a29e159b67da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n"
     ]
    }
   ],
   "source": [
    "# number of growth phases where 6 blocks == [4, 8, 16, 32, 64, 128]\n",
    "n_blocks = 6\n",
    "latent_dim = 100\n",
    "\n",
    "d_models = define_discriminator(n_blocks)\n",
    "g_models = define_generator(latent_dim, n_blocks)\n",
    "gan_models = define_composite(d_models, g_models)\n",
    "\n",
    "dataset = load_real_samples('img_align_celeba_128.npz')\n",
    "print('Loaded', dataset.shape)\n",
    "\n",
    "n_batch = [16, 16, 16, 8, 4, 4, 4, 2, 2]\n",
    "n_epochs = [5, 8, 8, 10, 10, 10, 10, 16, 16]\n",
    "\n",
    "train(g_models, d_models, gan_models, dataset, latent_dim, n_epochs, n_epochs, n_batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
